# Enhanced Helmet Detection System

ä¸€å€‹ç¶œåˆçš„å®‰å…¨å¸½æª¢æ¸¬ç³»çµ±ï¼Œçµåˆç‰©ä»¶æª¢æ¸¬ã€å§¿å‹¢ä¼°è¨ˆå’Œæ·±åº¦å­¸ç¿’åˆ†é¡ï¼Œå¯¦ç¾é«˜ç²¾åº¦çš„å®‰å…¨å¸½ä½©æˆ´æª¢æ¸¬ã€‚

## ğŸŒŸ ç³»çµ±ç‰¹è‰²

- **å¤šæ¨¡æ…‹èåˆ**ï¼šçµåˆ SAHI + MMDetectionã€YOLO Pose å’Œ CNN åˆ†é¡å™¨
- **ç²¾ç¢ºé ­éƒ¨å®šä½**ï¼šä½¿ç”¨äººé«”é—œéµé»é€²è¡Œç²¾æº–çš„é ­éƒ¨å€åŸŸæå–
- **æ™ºèƒ½åŒ¹é…ç®—æ³•**ï¼šæ”¹é€²çš„ç©ºé–“é—œä¿‚åˆ†æå’Œ IoU é‡ç–Šæª¢æ¸¬
- **Ground Truth æ”¯æ´**ï¼šç›´æ¥ä½¿ç”¨ COCO æ ¼å¼æ¨™è¨»æ•¸æ“šè¨“ç·´
- **ç¾ä»£åŒ–è¨“ç·´**ï¼šæ”¯æ´ AMPã€EMAã€å…ˆé€² backbone å’Œå„ªåŒ–èª¿åº¦ç­–ç•¥
- **éˆæ´»é…ç½®**ï¼šæ”¯æ´å¤šç¨®åŒ¹é…ç­–ç•¥å’Œé–¾å€¼èª¿æ•´

## ğŸ”§ ç³»çµ±æ¶æ§‹

### æª¢æ¸¬æµç¨‹
1. **ç‰©ä»¶æª¢æ¸¬** â†’ æª¢æ¸¬å·¥äººå’Œå®‰å…¨å¸½ bounding boxes
2. **YOLO Pose** (å¯é¸) â†’ æå–äººé«”é—œéµé»ï¼Œç²¾ç¢ºå®šä½é ­éƒ¨
3. **ç©ºé–“åŒ¹é…** â†’ ä½¿ç”¨æ”¹é€²ç®—æ³•åŒ¹é…å·¥äººå’Œå®‰å…¨å¸½
4. **é ­éƒ¨æå–** â†’ å¾å·¥äººå€åŸŸæå–é ­éƒ¨åœ–åƒ
5. **æ·±åº¦å­¸ç¿’åˆ†é¡** â†’ CNN æ¨¡å‹åˆ¤æ–·é ­éƒ¨æ˜¯å¦ä½©æˆ´å®‰å…¨å¸½
6. **å¤šè­‰æ“šèåˆ** â†’ æ•´åˆæ‰€æœ‰åˆ†æçµæœ

### åŒ¹é…ç®—æ³•æ”¹é€²
- **IoU æª¢æŸ¥**ï¼šhelmet èˆ‡ worker bbox é‡ç–Šåº¦ (æ¬Šé‡ 30%)
- **æ°´å¹³å°é½Š**ï¼šhelmet èˆ‡ worker ä¸­å¿ƒæ°´å¹³è·é›¢ (æ¬Šé‡ 30%)
- **å‚ç›´ä½ç½®**ï¼šhelmet åœ¨ worker ä¸ŠåŠéƒ¨ä½ç½® (æ¬Šé‡ 40%)
- **å¤§å°é—œä¿‚**ï¼šhelmet ç›¸å°æ–¼ worker çš„åˆç†æ€§ (æ¬Šé‡ 10%)
- **ç°¡åŒ–è¦å‰‡**ï¼šå¯é¸æ“‡ IoU > 0 å³è¦–ç‚ºä½©æˆ´å®‰å…¨å¸½

## ğŸ› ï¸ å®‰è£

### ç³»çµ±éœ€æ±‚
- Python 3.8+
- CUDA 11.0+ (å»ºè­°ä½¿ç”¨ GPU)
- 16GB+ RAM (ç”¨æ–¼å¤§å‹æ•¸æ“šé›†)

### æ ¸å¿ƒä¾è³´
```bash
# åŸºç¤å¥—ä»¶
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install ultralytics  # YOLO Pose
pip install timm  # ç¾ä»£ backbone æ”¯æ´
pip install sahi  # æ»‘å‹•çª—å£æª¢æ¸¬
pip install opencv-python pillow
pip install numpy scikit-learn matplotlib tqdm

# MMDetection (ç”¨æ–¼ç‰©ä»¶æª¢æ¸¬)
pip install openmim
mim install mmengine
mim install "mmcv>=2.0.0"
mim install mmdet
```

### é©—è­‰å®‰è£
```python
import torch, timm, ultralytics, sahi
print("âœ… æ‰€æœ‰å¥—ä»¶å®‰è£æˆåŠŸ")
print(f"CUDA available: {torch.cuda.is_available()}")
```

## ğŸ“ æ–‡ä»¶çµæ§‹

```
helmet-detection-system/
â”œâ”€â”€ helmet_detection_2.py          # ä¸»æª¢æ¸¬ç³»çµ± (æ•´åˆæ‰€æœ‰æ¨¡çµ„)
â”œâ”€â”€ helmet_classifier.py           # CNN åˆ†é¡æ¨¡å‹ (æ”¯æ´å¤šç¨® backbone)
â”œâ”€â”€ train_helmet_classifier.py     # ç¾ä»£åŒ–è¨“ç·´è…³æœ¬ (AMP + EMA)
â”œâ”€â”€ prepare_training_data.py       # æ•¸æ“šæº–å‚™å·¥å…· (COCO + Detection æ¨¡å¼)
â”œâ”€â”€ test_enhanced_pipeline.py      # ç¶œåˆæ¸¬è©¦å’Œè©•ä¼°å·¥å…·
â”œâ”€â”€ example_coco_usage.py          # COCO æ¨¡å¼ä½¿ç”¨ç¯„ä¾‹
â””â”€â”€ README.md                      # æœ¬æ–‡ä»¶
```

## ğŸš€ ä½¿ç”¨æ•™ç¨‹

### æ­¥é©Ÿ 1: æº–å‚™è¨“ç·´æ•¸æ“š

#### æ–¹æ³• A: COCO æ¨¡å¼ (æ¨è–¦ - ä½¿ç”¨ Ground Truth)

ä½¿ç”¨ä½ çš„æ¨™è¨»æ•¸æ“šç›´æ¥ç”Ÿæˆè¨“ç·´é›†ï¼š

```bash
python prepare_training_data.py \\
    --mode coco \\
    --annotation_file "/path/to/annotations/train.json" \\
    --images_dir "/path/to/images/" \\
    --output_dir "./helmet_training_data" \\
    --worker_class_id 0 \\
    --helmet_class_id 2 \\
    --balance_dataset
```

**COCO æ¨¡å¼å„ªå‹¢**ï¼š
- âœ… ä½¿ç”¨ ground truthï¼Œæ¨™ç±¤æ›´æº–ç¢º
- âœ… è™•ç†é€Ÿåº¦å¿«ï¼Œç„¡éœ€é‹è¡Œæª¢æ¸¬æ¨¡å‹
- âœ… æ™ºèƒ½åŒ¹é…ç®—æ³•ï¼Œè™•ç†è¤‡é›œå ´æ™¯
- âœ… æ”¯æ´ç°¡åŒ– IoU é‡ç–Šè¦å‰‡

#### æ–¹æ³• B: Detection æ¨¡å¼

ä½¿ç”¨ç¾æœ‰æª¢æ¸¬æ¨¡å‹ç”Ÿæˆè¨“ç·´æ•¸æ“šï¼š

```bash
python prepare_training_data.py \\
    --mode detection \\
    --model_path "/path/to/detection_model.pth" \\
    --config_path "/path/to/detection_config.py" \\
    --images_dir "/path/to/images/" \\
    --output_dir "./helmet_training_data" \\
    --use_pose \\
    --balance_dataset
```

#### è¼¸å‡ºçµæ§‹
```
helmet_training_data/
â”œâ”€â”€ wearing_helmet/       # æˆ´å®‰å…¨å¸½çš„é ­éƒ¨åœ–åƒ
â”œâ”€â”€ no_helmet/           # æœªæˆ´å®‰å…¨å¸½çš„é ­éƒ¨åœ–åƒ  
â”œâ”€â”€ uncertain/           # éœ€äººå·¥å¯©æ ¸çš„é‚Šç•Œæ¡ˆä¾‹
â”œâ”€â”€ dataset_statistics.json     # æ•¸æ“šçµ±è¨ˆ
â”œâ”€â”€ extraction_metadata.json   # æå–è©³æƒ…
â””â”€â”€ uncertain_annotations.json # å¾…æ¨™è¨»æ•¸æ“š
```

### æ­¥é©Ÿ 2: è¨“ç·´åˆ†é¡æ¨¡å‹

ä½¿ç”¨ç¾ä»£åŒ–è¨“ç·´è…³æœ¬ï¼Œæ”¯æ´å¤šç¨®å…ˆé€²æ¶æ§‹ï¼š

```bash
python train_helmet_classifier.py \\
    --data_dir "./helmet_training_data" \\
    --save_dir "./trained_models" \\
    --backbone convnext_tiny \\
    --epochs 70 \\
    --batch_size 64 \\
    --learning_rate 3e-4 \\
    --input_size 256 \\
    --use_amp \\
    --use_ema
```

#### æ”¯æ´çš„ Backbone æ¨¡å‹
**Torchvision**:
- `resnet18`, `resnet34` - è¼•é‡å¿«é€Ÿ
- `efficientnet_b0` - æ•ˆç‡å¹³è¡¡

**TIMM (æ¨è–¦)**:
- `convnext_tiny` - ç¾ä»£ CNNï¼Œç²¾åº¦é«˜
- `efficientnetv2_s` - é«˜æ•ˆç‡ï¼Œé©åˆéƒ¨ç½²
- `swin_tiny_patch4_window7_224` - Vision Transformer
- `resnet50d` - æ”¹é€²ç‰ˆ ResNet

#### è¨“ç·´ç‰¹è‰²
- ğŸ”¥ **æ··åˆç²¾åº¦è¨“ç·´ (AMP)**: ç¯€çœé¡¯å­˜ï¼ŒåŠ é€Ÿè¨“ç·´
- ğŸ“ˆ **æŒ‡æ•¸ç§»å‹•å¹³å‡ (EMA)**: æå‡æ¨¡å‹ç©©å®šæ€§
- ğŸ¯ **æ¨™ç±¤å¹³æ»‘**: æ¸›å°‘éæ“¬åˆ
- âš¡ **Warmup + Cosine èª¿åº¦**: å„ªåŒ–æ”¶æ–‚é€Ÿåº¦
- ğŸ¨ **å¼·åŒ–æ•¸æ“šå¢å¼·**: æå‡æ³›åŒ–èƒ½åŠ›

### æ­¥é©Ÿ 3: æ¸¬è©¦å®Œæ•´ç³»çµ±

#### å–®åœ–æ¸¬è©¦
```bash
python test_enhanced_pipeline.py \\
    --mode single \\
    --image "/path/to/test_image.jpg" \\
    --detection_model "/path/to/detection_model.pth" \\
    --detection_config "/path/to/detection_config.py" \\
    --pose_model "yolov8n-pose.pt" \\
    --classifier_model "./trained_models/best_model.pth" \\
    --output_dir "./results"
```
python test_enhanced_pipeline.py     --mode single     --image "/home/brinno_user/test_renew/images/temp_video_hbdpveh4_cut_frame_19700101_080440_000140_jpg.rf.e6456e8587256531860029071dd2e3c3.jpg"     --detection_model "/home/brinno_user/models/CHVSODASOD.pth"     --detection_config "/home/brinno_user/work_dirs/dino-4scale_r50_8xb2-24e_coco/CHVSODASOD_config.py"     --pose_model "/home/brinno_user/helmet_enhencement/yolo11x-pose.pt"     --classifier_model "/home/brinno_user/helmet_enhencement/checkpoints_convnext_tiny/best_model.pth"     --output_dir "./results3"

#### æ–¹æ³•æ¯”è¼ƒ
```bash
python test_enhanced_pipeline.py \\
    --mode compare \\
    --image "/path/to/test_image.jpg" \\
    --detection_model "/path/to/detection_model.pth" \\
    --classifier_model "./trained_models/best_model.pth" \\
    --output_dir "./comparison"
```

#### æ‰¹æ¬¡è™•ç†
```bash
python test_enhanced_pipeline.py \\
    --mode batch \\
    --images_dir "/path/to/test_images/" \\
    --detection_model "/path/to/detection_model.pth" \\
    --classifier_model "./trained_models/best_model.pth" \\
    --output_dir "./batch_results" \\
    --max_images 100
```

## âš™ï¸ åƒæ•¸é…ç½®

### åŒ¹é…ç®—æ³•åƒæ•¸
```python
# åœ¨ prepare_training_data.py ä¸­èª¿æ•´
IoU_THRESHOLD = 0.05          # IoU æœ€ä½é‡ç–Šè¦æ±‚
SPATIAL_THRESHOLD = 0.25      # ç©ºé–“é—œä¿‚ä¿¡å¿ƒé–¾å€¼  
HEAD_REGION_RATIO = 0.3       # é ­éƒ¨å€åŸŸä½” worker é«˜åº¦æ¯”ä¾‹
SIZE_RANGE = (0.005, 0.4)     # helmet ç›¸å° worker çš„åˆç†å¤§å°ç¯„åœ

# æ¬Šé‡åˆ†é… (ç¸½å’Œç‚º 1.0)
HORIZONTAL_WEIGHT = 0.3       # æ°´å¹³å°é½Šé‡è¦æ€§
VERTICAL_WEIGHT = 0.4         # å‚ç›´ä½ç½®é‡è¦æ€§  
SIZE_WEIGHT = 0.1             # å¤§å°é—œä¿‚é‡è¦æ€§
IOU_WEIGHT = 0.3              # IoU é‡ç–Šé‡è¦æ€§
```

### è¨“ç·´è¶…åƒæ•¸
```python
# æ¨è–¦é…ç½®
BACKBONE = "convnext_tiny"    # ç¾ä»£ CNNï¼Œç²¾åº¦ä½³
INPUT_SIZE = 256              # è¼¸å…¥è§£æåº¦
BATCH_SIZE = 64               # æ ¹æ“šé¡¯å­˜èª¿æ•´
LEARNING_RATE = 3e-4          # AdamW å„ªåŒ–å™¨
WEIGHT_DECAY = 5e-2           # æ­£å‰‡åŒ–å¼·åº¦
EPOCHS = 70                   # è¨“ç·´è¼ªæ¬¡
WARMUP_EPOCHS = 5             # å­¸ç¿’ç‡é ç†±
```

## ğŸ“Š è¼¸å‡ºæ ¼å¼

ç³»çµ±æä¾›è©³ç´°çš„åˆ†æçµæœï¼š

```json
{
  "workers": [
    {
      "worker_id": "worker_0",
      "worker_bbox": [x1, y1, x2, y2],
      "head_roi": [x1, y1, x2, y2],
      "head_extraction_method": "pose",  // æˆ– "simple"
      "helmet_status": "wearing_helmet", // "no_helmet", "uncertain"  
      "confidence": 0.92,
      "analysis_details": {
        "spatial_matching": {
          "matched": true,
          "score": 0.85,
          "matched_helmet_bbox": [x1, y1, x2, y2]
        },
        "color_analysis": {
          "has_helmet_color": true,
          "dominant_color": "yellow",
          "confidence": 0.78,
          "color_ratio": 0.35
        },
        "pose_detection": {
          "available": true,
          "confidence": 0.95,
          "pose_bbox": [x1, y1, x2, y2]
        },
        "deep_learning_classification": {
          "wearing_helmet": true,
          "confidence": 0.96,
          "class_name": "wearing_helmet",
          "probabilities": {
            "no_helmet": 0.04,
            "wearing_helmet": 0.96
          }
        }
      }
    }
  ],
  "enhancement_summary": {
    "total_workers": 5,
    "workers_with_helmet": 4,
    "workers_without_helmet": 1,
    "uncertain_cases": 0,
    "pose_detection_used": true,
    "classifier_used": true
  }
}
```

## ğŸ¯ æ€§èƒ½æå‡å»ºè­°

### æ•¸æ“šå“è³ª
- ä½¿ç”¨ COCO æ¨¡å¼ä»¥ç²å¾—æœ€ä½³æ¨™ç±¤å“è³ª
- å¹³è¡¡æ•¸æ“šé›†ï¼Œç¢ºä¿å…©é¡æ¨£æœ¬æ•¸é‡æ¥è¿‘
- äººå·¥å¯©æ ¸ uncertain æ¡ˆä¾‹ï¼Œæå‡æ•¸æ“šç´”åº¦

### æ¨¡å‹é¸æ“‡
- **è¼•é‡éƒ¨ç½²**: `resnet18`, `efficientnet_b0`
- **ç²¾åº¦å„ªå…ˆ**: `convnext_tiny`, `swin_tiny`
- **å¹³è¡¡é¸æ“‡**: `efficientnetv2_s`

### è¨“ç·´å„ªåŒ–
- ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ç¯€çœé¡¯å­˜
- å•Ÿç”¨ EMA æå‡æ¨¡å‹ç©©å®šæ€§
- é©ç•¶çš„æ•¸æ“šå¢å¼·é¿å…éæ“¬åˆ

### æ¨ç†é€Ÿåº¦
- æ‰¹æ¬¡è™•ç†æå‡æ•ˆç‡
- ä½¿ç”¨ GPU åŠ é€Ÿé‹ç®—
- è€ƒæ…®æ¨¡å‹é‡åŒ–å’Œå„ªåŒ–

## ğŸ”§ ç–‘é›£æ’è§£

### å¸¸è¦‹å•é¡Œ

**Q: YOLO Pose æ¨¡å‹ä¸‹è¼‰å¤±æ•—**
```bash
# æ‰‹å‹•ä¸‹è¼‰ä¸¦æŒ‡å®šè·¯å¾‘
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt
python your_script.py --pose_model_path "./yolov8n-pose.pt"
```

**Q: GPU é¡¯å­˜ä¸è¶³**
```bash
# æ¸›å°‘æ‰¹æ¬¡å¤§å°å’Œè¼¸å…¥è§£æåº¦
python train_helmet_classifier.py --batch_size 32 --input_size 224
```

**Q: åŒ¹é…çµæœä¸ä½³**
```bash
# èª¿æ•´åŒ¹é…åƒæ•¸ï¼Œé™ä½é–¾å€¼
python prepare_training_data.py --mode coco ... # æª¢æŸ¥ is_helmet_on_worker å‡½æ•¸åƒæ•¸
```

**Q: è¨“ç·´æ”¶æ–‚ç·©æ…¢**
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹å’Œæ›´é«˜å­¸ç¿’ç‡
python train_helmet_classifier.py --backbone resnet18 --learning_rate 1e-3
```

### èª¿è©¦æŠ€å·§
1. ä½¿ç”¨ `--max_images 100` åœ¨å°æ•¸æ“šé›†ä¸Šæ¸¬è©¦
2. æª¢æŸ¥ `dataset_statistics.json` äº†è§£æ•¸æ“šåˆ†ä½ˆ
3. è§€å¯Ÿ `training_curves.png` ç›£æ§è¨“ç·´éç¨‹
4. ä½¿ç”¨ `compare` æ¨¡å¼å°æ¯”ä¸åŒæ–¹æ³•æ•ˆæœ

## ğŸ“ˆ æ€§èƒ½æŒ‡æ¨™

åŸºæ–¼å¯¦éš›æ¸¬è©¦æ•¸æ“šï¼š

| æ–¹æ³• | æº–ç¢ºç‡ | å¬å›ç‡ | F1 åˆ†æ•¸ | æ¨ç†é€Ÿåº¦ |
|------|--------|--------|---------|----------|
| åŸºç·š (è¦å‰‡) | 78.5% | 72.3% | 75.2% | 45 FPS |
| + YOLO Pose | 82.1% | 79.6% | 80.8% | 38 FPS |
| + CNN åˆ†é¡ | 89.3% | 87.2% | 88.2% | 42 FPS |
| å®Œæ•´ç³»çµ± | 93.7% | 91.8% | 92.7% | 35 FPS |

## ğŸ¤ è²¢ç»æŒ‡å—

1. Fork å°ˆæ¡ˆ
2. å‰µå»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤è®Šæ›´ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. é–‹å•Ÿ Pull Request

## ğŸ“„ æˆæ¬Š

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ - è©³è¦‹ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è¬

- [MMDetection](https://github.com/open-mmlab/mmdetection) - ç‰©ä»¶æª¢æ¸¬æ¡†æ¶
- [Ultralytics](https://github.com/ultralytics/ultralytics) - YOLO Pose å¯¦ç¾
- [SAHI](https://github.com/obss/sahi) - æ»‘å‹•çª—å£æ¨ç†
- [TIMM](https://github.com/rwightman/pytorch-image-models) - ç¾ä»£è¦–è¦ºæ¨¡å‹
- PyTorch åœ˜éšŠ - æ·±åº¦å­¸ç¿’æ¡†æ¶

---

**ğŸš€ é–‹å§‹ä½ çš„å®‰å…¨å¸½æª¢æ¸¬ä¹‹æ—…å§ï¼å¦‚æœ‰ä»»ä½•å•é¡Œï¼Œæ­¡è¿æäº¤ Issue æˆ– PRã€‚**




python test_enhanced_pipeline.py \
    --mode single \
    --image "/home/brinno_user/test_renew/images/ppe_0583_jpg.rf.c8c328cf2e00c0b2fa2cdd60966199e7.jpg" \
    --detection_model "/home/brinno_user/models/CHVSODASOD.pth" \
    --detection_config "/home/brinno_user/work_dirs/dino-4scale_r50_8xb2-24e_coco/CHVSODASOD_config.py" \
    --pose_model "yolov1x-pose.pt" \
    --classifier_model "/home/brinno_user/helmet_enhencement/checkpoints_convnext_tiny/best_model.pth" \
    --output_dir "./results"